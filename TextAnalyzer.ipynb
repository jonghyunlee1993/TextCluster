{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81fa2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "class TextAnalyzer:\n",
    "    def __init__(self, project, column_of_interest, number_of_cluster):\n",
    "        self.project = project\n",
    "        self.column_of_interest = column_of_interest\n",
    "        self.number_of_cluster = number_of_cluster\n",
    "        \n",
    "        with open(\"key/openai_key.txt\", \"r\") as f:\n",
    "            OPENAI_API_KEY = f.readlines()[0].rstrip()\n",
    "            \n",
    "        openai.api_key = OPENAI_API_KEY\n",
    "        self.load_text_model()\n",
    "        \n",
    "        self.df = pd.read_excel(f\"data/{self.project}.xlsx\", engine=\"openpyxl\")\n",
    "    \n",
    "    def load_text_model(self):\n",
    "        # Base Model (108M)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")\n",
    "        self.model = AutoModelWithLMHead.from_pretrained(\"beomi/kcbert-base\").eval()\n",
    "\n",
    "    def run_analyze(self):\n",
    "        print(\"Step 1/4: Encode text\\n\")\n",
    "        features = self.get_feature()\n",
    "        print(\"Step 2/4: Get cluster labels\\n\")\n",
    "        self.get_cluster(features)\n",
    "        print(\"Step 3/4: Get theme of each clusters\\n\")\n",
    "        self.get_theme()\n",
    "        print(\"Step 4/4: Write results excel file\\n\")\n",
    "        self.write_results()\n",
    "        \n",
    "    def get_feature(self):\n",
    "        feature = []\n",
    "\n",
    "        for i, line in tqdm(self.df.iterrows(), total=len(self.df)):\n",
    "            token = self.tokenizer(line[self.column_of_interest].replace(\"\\n\", \" \"), return_tensors=\"pt\")\n",
    "            out = self.model.bert(**token)\n",
    "            cls = out['last_hidden_state'][:, 0, :].squeeze(0).detach().numpy().tolist()\n",
    "            feature.append(cls)\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def get_cluster(self, features):\n",
    "        kmeans = KMeans(\n",
    "            init=\"random\",\n",
    "            n_clusters=self.number_of_cluster,\n",
    "            n_init=10,\n",
    "            max_iter=100,\n",
    "            random_state=42\n",
    "        ).fit(features)\n",
    "\n",
    "        self.df.loc[:, \"cluster\"] = kmeans.labels_\n",
    "\n",
    "    def get_theme(self):\n",
    "        self.theme_dict = {}\n",
    "\n",
    "        for i in tqdm(range(self.df.cluster.max() + 1)):\n",
    "            subset = self.df.loc[self.df.cluster == i, self.column_of_interest].values.tolist()\n",
    "            if len(subset) > 50:\n",
    "                import random \n",
    "                random.shuffle(subset)\n",
    "                subset = subset[:50]\n",
    "            \n",
    "            answer = self.query_chatGPT(subset)\n",
    "            self.theme_dict[i] = answer\n",
    "        \n",
    "        self.df.loc[:, \"theme\"] = self.df.cluster.map(lambda x: self.theme_dict[x])\n",
    "\n",
    "    def query_chatGPT(self, query_text, LLM_model=\"gpt-3.5-turbo\"):\n",
    "        query = f\"\"\"\n",
    "            다음 문장을 읽고 주제를 한 줄로 요약해라. 다음 템플릿을 사용하라.:\n",
    "\n",
    "            TEXT: {str(query_text)}\n",
    "\n",
    "            TEMPLATE:\n",
    "            주제: {'write here the main theme of given texts'}\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=LLM_model,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        answer = response['choices'][0]['message']['content']\n",
    "\n",
    "        return answer\n",
    "        \n",
    "    def write_results(self):\n",
    "        df_stat = (self.df.loc[:, [\"theme\", self.column_of_interest]].groupby(\"theme\").count() / len(self.df) * 100).round(2)\n",
    "        with pd.ExcelWriter(f\"results/{self.project}_results.xlsx\", engine='xlsxwriter') as writer:\n",
    "            df_stat.to_excel(writer, sheet_name=\"Summary\", index=True)\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[\"Summary\"]\n",
    "            worksheet.set_column('A:A', 100)\n",
    "\n",
    "            for i in range(self.df.cluster.max() + 1):\n",
    "                df_subset = self.df.loc[self.df.cluster == i].iloc[:, :-2]\n",
    "                df_subset.to_excel(writer, sheet_name=f\"Cluster_{i}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d59a20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/4: Encode text\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee14f7d3c6b74d8e8da4a7a47a3da44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2/4: Get cluster labels\n",
      "\n",
      "Step 3/4: Get theme of each clusters\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc0cfbcebc84d4a80996fddae252469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4/4: Write results excel file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = TextAnalyzer(project=\"sample_data\", column_of_interest=\"의견\", number_of_cluster=5)\n",
    "analyzer.run_analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4366fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c138318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
